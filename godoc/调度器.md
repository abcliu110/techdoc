<div id="chap-goroutineschedule"></div>

[⬆️ 返回目录](#catalog)


## 调度器


简短的回答是：**是的，你的理解非常准确。**

Go 语言中 `g0` 之所以能“适应”系统栈（System Stack），最核心的原因就是 **`g0` 的栈内存直接对应了操作系统线程（M）本身的栈内存**。

下面详细拆解一下这个机制和原因：

### 1. 什么是 `g0` 与 `M` 的关系？

在 Go 的 GMP 模型中：
*   **M (Machine)**：对应一个内核级线程（OS Thread）。
*   **g0**：是每个 M 上绑定的第一个 Goroutine。它是一个特殊的 Goroutine，不是由用户代码创建的，而是由 Runtime 在启动 M 时自动创建的。

**关键点：** `g0` 仅仅是一个 `G` 结构体，但它的栈（Stack）直接指向了 M 线程被操作系统分配的原始栈空间。

### 2. 为什么 `g0` 不需要像普通 G 那样动态扩容？

*   **普通 G**：初始栈很小（通常是 2KB），需要根据深度动态扩容（Copy Stack）。
*   **g0**：它的栈大小就是操作系统线程栈的大小（在 Linux 上通常是 8MB，在 Windows 上通常是 1MB+）。这个空间对于 Go Runtime 的调度、垃圾回收（GC）代码来说已经足够巨大，几乎不可能溢出。

因此，`g0` 不需要检查栈溢出，也不需要动态扩容，它天然就是“系统栈”。

### 3. `g0` 能适应系统栈的真正原因（技术细节）

当你听到“在系统栈上执行”时，在 Go Runtime 的源码中通常对应 `systemstack` 这个函数。它的工作原理如下：

1.  **指针切换**：当普通 G 需要进行一些底层操作（如调度、分配栈、GC 扫描）时，调用 `systemstack`。
2.  **保存现场**：Runtime 会把当前普通 G 的寄存器（PC, SP 等）保存到该 G 的 `sched` 结构中。
3.  **切换 SP**：Runtime 将 CPU 的栈指针（SP）寄存器直接修改为当前 **M 的 `g0` 的栈指针**。
4.  **执行代码**：此时 CPU 实际上正在使用 M 的线程栈（也就是系统栈）来执行代码。
5.  **切回**：执行完后，再把 SP 切回普通 G 的栈。

### 4. 为什么要这么设计？（根本原因）

如果 `g0` 不使用系统栈，会有严重的 **“鸡生蛋，蛋生鸡”** 问题：

1.  **栈扩容死循环**：
    如果普通 G 的栈满了，它需要调用 Runtime 代码（`morestack`）来分配一个更大的新栈。
    *   如果 Runtime 分配栈的代码也跑在这个已经满了的普通 G 栈上，会直接导致 Stack Overflow（因为没空间跑“分配空间”的代码了）。
    *   **解决方案**：切换到 `g0`（系统栈），因为 `g0` 的栈非常大且固定，可以安全地执行“内存分配”和“栈拷贝”的逻辑。

2.  **CGO 与 系统调用**：
    C 语言代码（CGO）或者操作系统的内核代码往往假设栈是标准的、连续的且足够大的（即系统栈）。它们不懂 Go 的动态栈机制。
    *   **解决方案**：通过切换到 `g0`，Go 能够提供一个符合 C 语言/操作系统规范的栈环境来执行 C 代码或处理复杂的系统调用。

### 总结

`g0` 能适应系统栈，本质上是因为：
**`g0` 就是 M 的影子。** `g0` 的 `stack.lo` 和 `stack.hi`（栈边界）圈定的内存范围，就是操作系统分配给该线程的内存范围。所以在 `g0` 上跑，就是在系统栈上跑。

这是一个非常敏锐的问题！你触及了 Go 运行时设计的本质。

你说的完全正确：**M（线程）本身就有操作系统分配的栈，确实可以直接执行代码。**

那么，为什么 Go 还要多此一举，非要弄一个 `g0` 结构体来“包装”这个 M 的栈，并强行称之为“协程”呢？

根本原因在于：**为了统一世界的视图（Uniformity）和 解决“自我管理”的悖论。**

以下是 4 个具体的硬核理由：

### 1. Go 运行时的“自举”特性 (Go Runtime is written in Go)

Go 的 Runtime（调度器、GC、内存分配）绝大部分是用 **Go 语言** 写的，而不是 C 语言。

*   **Go 代码的假设**：任何一段 Go 代码执行时，都默认自己属于某个 `G`（Goroutine）。
*   **依赖 G 的上下文**：Go 的编译器和标准库在底层严重依赖 `G` 结构体。
    *   例如：`getg()` 获取当前协程信息。
    *   例如：`defer` 链表挂在 `G` 结构体上。
    *   例如：`panic`/`recover` 机制需要去 `G` 里面找捕获点。
*   **如果不封装 `g0`**：
    如果 M 线程直接“裸奔”执行 Runtime 的 Go 代码，那么这段代码执行时 `getg()` 会返回空，`defer` 没地方挂，`panic` 没法处理。
    **结论**：为了让 Runtime 的 Go 代码能正常跑起来，必须给 M 的系统栈穿上一层 `G` 的“外衣”，这就是 `g0`。

### 2. 调度器的“中转站”作用

想象一下，CPU 正在执行用户协程 `G1`，现在决定要切换到用户协程 `G2`。

*   **问题**：你不能直接从 `G1` 的栈跳到 `G2` 的栈。
*   **原因**：调度逻辑本身（比如寻找下一个可运行的 G、将 G1 放回队列、解锁等）需要消耗栈空间。
    *   如果我们在 `G1` 的栈上执行调度代码，万一 `G1` 的栈刚好满了怎么办？（栈溢出）。
    *   如果我们直接跳到 `G2`，但还没决定好是不是选 `G2` 怎么办？
*   **解决**：我们需要一个 **“绝对安全、空间巨大、永远在线”** 的地方来运行调度器代码（`schedule()` 函数）。
    *   `g0` 就是这个中转站。
    *   流程是：`G1` -> 切换到 `g0` (保存 G1 上下文) -> **在 g0 上运行调度逻辑** -> 找到 `G2` -> 切换到 `G2` (恢复 G2 上下文)。

### 3. 解决“栈扩容”的“鸡生蛋”悖论

这是最技术性的原因。

*   **场景**：用户协程 `G1` 的栈满了（Stack Overflow），触发了扩容机制。
*   **任务**：Runtime 需要申请一块新的、更大的内存，把 `G1` 旧栈的数据拷贝过去。
*   **悖论**：
    *   “申请内存”和“拷贝数据”这些代码本身也是函数调用，也需要消耗栈空间。
    *   但是 `G1` 的栈已经满了，容不下任何额外的函数调用了。
    *   如果在 `G1` 上执行“扩容代码”，会直接导致真正的 Crash。
*   **解决**：
    *   一旦检测到栈溢出，立刻切换到 `g0`。
    *   `g0` 拥有巨大的系统栈（比如 8MB），完全可以轻松执行“申请内存、拷贝数据”的逻辑。
    *   搞定后，再切回 `G1` 的新栈。

### 4. 统一 GC（垃圾回收）的扫描视角

Go 的 GC 需要扫描所有的栈来寻找存活的对象指针。

*   如果 M 直接运行代码而没有 `g0` 结构体，GC 就必须编写两套逻辑：
    1.  一套用来扫描普通 `G` 的栈。
    2.  一套专门用来扫描“裸奔线程 M”的系统栈。
*   **抽象统一**：有了 `g0`，M 的系统栈在 GC 看来也就是一个特殊的 `G` 而已。`g0` 结构体里记录了 `stack.lo` 和 `stack.hi`，GC 拿到这个结构体，就能用通用的逻辑去扫描系统栈上的指针。

---

### 总结

并不是因为 M 的栈不能用，而是为了**用 Go 语言的方式来管理 Go 语言**。

`g0` 本质上是一个 **Adapter（适配器）模式**：
*   **Backend**：是 M 拥有的、操作系统分配的原始线程栈（Raw OS Stack）。
*   **Interface**：是 `G` 结构体。
*   **Result**：`g0`。

它把底层的“系统线程栈”伪装成了一个“Go 协程”，使得 Go Runtime 的代码（调度、GC、分配）可以在一个统一的 `G` 上下文中运行，同时利用了系统栈空间大的优势来处理高风险操作（如栈扩容）。


你切入到了 Go Runtime 调度器设计非常核心的一个点。

简单直接的回答是：**Go 确实没有针对成千上万个具体的系统调用（如 `read`, `write`, `mmap`, `ioctl` 等）分别写判断逻辑，而是采用了“统一入口拦截”和“独立监控线程”相结合的机制。**

Go 不是在业务层判断“这个函数是不是系统调用”，而是在**底层汇编入口处**做了统一的“钩子（Hook）”。

以下是 Go 处理这个问题的具体机制，分为三个层面来理解：

### 1. 统一的汇编入口（Hook 机制）

Go 的标准库 `syscall` 包中，所有系统调用最终都会走到几个核心的汇编函数，例如 `Syscall`、`Syscall6`（带6个参数）、`RawSyscall` 等。

并不是 Go 针对 `Open` 写一段逻辑，针对 `Read` 写一段逻辑。而是所有的 `Open`、`Read` 最终都会调用 `Syscall(trap, args...)`。

在这个 `Syscall` 汇编函数的内部，Go 插入了两个关键的 Runtime 函数调用：

1.  **`runtime.entersyscall()`**: 在真正执行汇编指令（如 `INT 0x80` 或 `SYSCALL`）陷入内核**之前**调用。
2.  **`runtime.exitsyscall()`**: 在系统调用返回、切回用户态**之后**调用。

**所以，不需要判断成百上千个系统调用，只需要把守住这几个通用的入口函数就行了。**

#### `entersyscall` 做的事情：
*   **保存上下文**：保存当前的 PC（程序计数器）和 SP（栈指针）。
*   **状态标记**：将当前的 G（Goroutine）状态置为 `_Gsyscall`，将 M（线程）状态置为 `_Psyscall`。
*   **解绑 P（乐观策略）**：此时 M 并没有完全释放 P（Processor），而是让 P 进入一种“我正在忙系统调用，但可能马上回来”的状态。此时 P 依然指向 M，但 P 的状态变成了 `_Psyscall`。

### 2. Sysmon：全知全能的监控者（兜底机制）

如果每个系统调用都立刻把 P（处理器资源）完全剥离，开销太大，因为很多系统调用（如获取时间、很小的读取）纳秒级就返回了。

所以，Go 引入了一个完全独立于调度循环之外的系统监控线程，叫做 **`sysmon`**（System Monitor）。它不需要绑定 P 就能运行。

`sysmon` 会在一个循环中不断检查所有的 P：

1.  它发现某个 P 处于 `_Psyscall` 状态。
2.  它会看这个 P 处于该状态多久了。
3.  **如果超过 10ms（一个 tick）**，`sysmon` 就会认为：“这个 M 被系统调用真正阻塞住了（比如在读大文件或 CGO）”。
4.  **抢占 P（Handoff）**：`sysmon` 会强制把这个 P 从那个阻塞的 M 身上拿走，并将 P 重新分配给其他的 M（如果需要，会唤醒或新建一个 M），让 P 去执行队列里其他的 G。

**这就是“不需要每个系统调用都判断”的秘诀：由后台监控线程来异步判断是否需要调度，而不是由调用方同步判断。**

### 3. CGO 的处理逻辑

CGO 的原理和系统调用非常类似，但它调用的函数是 `runtime.cgocall`。

当 Go 调用 C 函数时：
1.  调用 `entersyscall`（没错，CGO 复用了系统调用的逻辑）。
2.  进入 C 的世界，M 被 C 代码占用（如果 C 代码阻塞，M 就阻塞）。
3.  如果 C 代码执行时间过长，`sysmon` 同样会把 P 抢走。
4.  C 代码返回时，调用 `exitsyscall`，M 尝试找回 P，如果有空闲 P 就拿一个，没有就入队等待。

### 特例：网络 I/O (Netpoller)

你提到的“读取大文件”属于**文件 I/O**，它确实会阻塞 M。

但是，Go 对**网络 I/O**（TCP/UDP）做了特殊优化，并没有走上面的阻塞 M 流程：

*   Go 将网络 socket 设置为 **Non-blocking（非阻塞）** 模式。
*   当你在 Go 里调用 `conn.Read()` 时，如果数据没准备好，Go **不会** 调用阻塞的系统调用让 OS 挂起 M。
*   相反，Go 调用 `epoll_ctl` (Linux) 或 `kqueue` (Mac) 注册事件，然后把当前的 G 挂起（状态变为 `_Gwaiting`），**把 M 让出来去执行别的 G**。
*   等到网络数据到了，Netpoller 线程会通知 Runtime，把刚才那个 G 唤醒。

**结论：**
对于网络 I/O，Go 甚至都不让 M 进入系统调用的阻塞状态；
对于文件 I/O 和 CGO，Go 依靠 **Unified Entry Hook (`entersyscall`)** + **Sysmon Monitor** 来自动管理 M 和 P 的分离，从而避免了针对每个系统调用写硬编码逻辑。

这是一个非常深刻且触及 Go 运行时核心设计哲学的问题。

首先，直接回答你的疑虑：**数据绝对不会丢失。**

你的前提只对了一半：**Go 调度器在切换 Goroutine 时，确实往往不保存浮点寄存器（Floating Point Registers）和 AVX/SSE 等庞大的向量寄存器到 `gobuf` 中。**

之所以不会丢失数据，是因为 Go 采用了与操作系统线程完全不同的**“协作式”与“编译器辅助”**的策略。

以下是详细的硬核解释：

---

### 1. 核心秘密：调度发生的时机（主动 vs 被动）

要理解为什么不需要保存，必须理解 Goroutine 切换通常发生在什么地方。

#### 操作系统线程（OS Thread）的切换 —— “被动且盲目”
操作系统进行线程切换通常是**抢占式**的（例如时钟中断）。
*   **场景**：线程正在进行复杂的矩阵运算，AVX-512 寄存器里塞满了数据。突然，CPU 中断来了，操作系统强行切走。
*   **OS 的困境**：操作系统不知道这个线程刚才在干嘛，也不知道哪些寄存器是有用的。为了安全，它必须**把所有寄存器（整数、浮点、向量）全部保存**到内存中。这是一次非常昂贵的操作（尤其是现代 CPU 寄存器组越来越大）。

#### Go Goroutine 的切换 —— “主动且有准备”
Go 的调度（大部分情况下）是发生在**用户态**的，而且往往发生在**函数调用边界**或**运行时系统调用**时。
*   **场景**：代码运行到 `channel <- data` 或者调用了一个函数。
*   **编译器的魔法**：Go 编译器知道这里可能会发生调度。根据**调用规约（Calling Convention）**，如果当前寄存器里有正在使用的浮点数，编译器会在调用 runtime 函数（导致调度）之前，生成指令**把这些寄存器的值“溢出”（Spill）到 Goroutine 自己的栈（Stack）上**。

**结论**：
当调度器真正介入（执行汇编代码 `mcall` 或 `gogo`）去切换上下文时，**所有重要的浮点数数据已经被编译器安全地放在栈上了**。调度器只需要保存极少量的整数寄存器（主要是栈指针 SP、指令指针 PC、基址指针 BP），切换成本极低。

---

### 2. 深入：`gobuf` 结构体
在 Go 的运行时源码（`runtime/runtime2.go`）中，保存 Goroutine 上下文的结构体叫 `gobuf`。你看它有多小：

```go
type gobuf struct {
    sp   uintptr        // Stack Pointer (栈指针)
    pc   uintptr        // Program Counter (指令指针)
    g    guintptr       // 指向绑定的 g 结构体
    ctxt unsafe.Pointer // 上下文
    ret  uintptr        // 返回地址
    lr   uintptr        // Link Register (ARM 等架构用)
    bp   uintptr        // Base Pointer (基址指针)
}
```
**看，里面完全没有浮点寄存器（XMM/YMM/ZMM）的位置！**
因为它根本不需要在调度器层面保存。恢复执行时，调度器只需恢复 SP 和 PC，代码回到原来的逻辑流中，编译器生成的后续指令会负责从栈上把浮点数加载回寄存器。

---

### 3. 特殊情况：Go 1.14+ 的异步抢占（Asynchronous Preemption）

你可能会问：*“如果我写了一个死循环计算浮点数，从来不调用函数，Go 怎么切？切了会不会丢数据？”*

在 Go 1.14 之前，这种死循环会导致其他 Goroutine 饿死。但 Go 1.14 引入了**基于信号的异步抢占**。

*   **场景**：一个 Goroutine 在执行密集计算，没有主动让出。
*   **机制**：系统线程发送一个信号（如 `SIGURG`）给该线程。
*   **处理**：这是一个类似操作系统的中断。在这种**不可预知**的时间点进行抢占时，Go 的信号处理函数（Signal Handler）**确实必须保存所有寄存器状态**（包括浮点寄存器）。
    *   它会利用操作系统提供的 `ucontext` 或 `sigcontext` 来保存完整的现场。
    *   这种切换比普通的协作式切换要慢，但在 Go 中属于“兜底”机制，不是常态。

---

### 总结

Go 之所以不需要在常规切换（`gobuf`）中保存浮点寄存器，是因为：

1.  **责任转移**：Go 把保存数据的责任交给了**编译器**，而不是**调度器**。
2.  **栈的使用**：编译器在发生潜在调用的位置，会自动将活跃的寄存器值压入 **Goroutine 的栈**中。
3.  **轻量级切换**：调度器只需要切换栈指针（SP），就像换了一张办公桌。至于桌子上该摆什么文件（寄存器数据），是你坐下来之后（恢复执行后），根据之前的记录（栈上的数据）自己拿出来的。

所以，**速度快是因为只做了必要的工作，而数据安全则是由编译器的严谨逻辑来保证的。**

这是一个非常深入底层的问题。要理解编译器“自动保存”的机制，我们需要打破一个常见的误解：

**编译器并不是专门为“协程切换”生成了特殊的保存代码，而是利用了通用的“函数调用规约（Calling Convention）”和“活跃性分析（Liveness Analysis）”机制。**

换句话说，对于编译器而言，**“发生协程切换”和“调用一个普通函数”在保存寄存器数据这一步上，几乎是一样的。**

下面为您详细拆解这个过程：

---

### 1. 核心机制：调用规约 (Calling Convention)

Go 1.17 引入了基于寄存器的 ABI（应用程序二进制接口）。这意味着函数参数和返回值尽量通过寄存器传递。但是，寄存器数量是有限的，且会被不同的函数复用。

为了解决冲突，编译器遵循一套规则，主要分为两类寄存器：

*   **Caller-Save (调用者保存)**：如果我在调用子函数后，还需要用到这个寄存器里的值，**我（调用者）**必须在调用前把它存到栈上。
*   **Callee-Save (被调用者保存)**：子函数如果想用这个寄存器，必须先把它原来的值存起来，等子函数执行完再恢复。

**Go 的策略**：
Go 并没有严格依赖传统的 Callee-Save 寄存器（像 C 语言那样）。Go 的编译器非常智能，它主要依赖**Caller-Save** 逻辑结合**栈溢出（Spill）**。

#### 具体的“自动保存”流程：

假设你的代码是这样的：

```go
func physicsCalculation() {
    // 1. 这是一个复杂的浮点运算，结果在 XMM0 寄存器中
    x := 3.14 * 2.0 
    
    // 2. 这里调用了 time.Sleep，这会导致协程切换！
    time.Sleep(time.Second) 
    
    // 3. 恢复后继续使用 x
    println(x)
}
```

**编译器的视角（汇编生成逻辑）：**

1.  **活跃性分析 (Liveness Analysis)**：
    编译器扫描代码，发现变量 `x` 在第 1 行生成（在寄存器中），但在第 2 行的函数调用 `time.Sleep` **之后**，第 3 行还要用到 `x`。

2.  **生成溢出指令 (Spilling)**：
    因为 `time.Sleep` 是一个函数调用，它可能会修改寄存器（它内部肯定会用到寄存器）。
    所以，编译器会在**调用 `time.Sleep` 之前**，插入一条指令：
    `MOVSD XMM0, 24(SP)` （把 XMM0 寄存器的值挪到当前协程的栈内存中，偏移量为24的位置）。

3.  **执行调用**：
    执行 `CALL time.Sleep`。
    *注意：此时重要的浮点数据已经在栈上了，寄存器里的数据丢了也无所谓。*

4.  **协程切换发生**：
    `time.Sleep` 内部最终调用了 `runtime.gopark`，调度器介入。调度器只保存了 SP（栈顶在哪里）和 PC（代码执行到哪里）到 `gobuf`。
    **调度器完全不关心 XMM0，因为 XMM0 的值已经在第 2 步被编译器“安全备份”到栈里了。**

---

### 2. 为什么说“切换”只是“函数调用”的副作用？

你可能认为协程切换是一个特殊的“魔法时刻”，但对 CPU 而言，它只是通过层层函数调用，最终停在了一个特定的汇编指令上。

**调用链示例：**
`UserFunction` -> `time.Sleep` -> `runtime.timeSleep` -> `runtime.gopark` -> `runtime.mcall`

在这个链条中，每一层函数调用都会遵循上述的“保存必要数据到栈上”的规则。

*   当执行到 `runtime.mcall` 准备切换 G 时，**所有之前函数（用户代码）产生的、后续还需要使用的活跃数据，都已经一层一层地被“压”在栈上了。**
*   `gobuf` 只需要记下：“这个协程的栈顶（SP）在哪里”。

只要记住了栈顶，也就找回了之前保存的所有寄存器数据。

---

### 3. 恢复执行时的“自动恢复”

当协程被唤醒时，流程是反过来的：

1.  **调度器恢复**：调度器把 CPU 的 SP 寄存器指回该协程的栈地址，把 PC 指向 `runtime.gopark` 之后的指令。
2.  **函数返回 (Return)**：`runtime.gopark` 返回 -> `runtime.timeSleep` 返回 -> `time.Sleep` 返回。
3.  **编译器生成的恢复代码**：
    回到 `physicsCalculation` 函数中，在 `CALL time.Sleep` 指令的下一行。
    编译器早在编译阶段就生成好了对应的恢复指令：
    `MOVSD 24(SP), XMM0` （把栈里的数据读回寄存器）。
4.  **继续执行**：现在 XMM0 里又是 6.28 了，程序继续执行 `println(x)`。

---

### 4. 唯一的例外：异步抢占 (Preemption)

我在上一个回答中提到了 **Go 1.14+ 的异步抢占**，这是唯一**编译器无法预测**的情况。

*   **场景**：代码在一个 `for` 循环里死算，不调用任何函数。
*   **问题**：因为没有函数调用，编译器就没有机会插入“保存寄存器到栈”的指令。
*   **解决**：操作系统给线程发信号（Signal）。
*   **处理**：信号处理函数（Signal Handler）是由操作系统调用的，它会把**当前 CPU 所有寄存器的快照**（Context）保存在内存里（通常是 `ucontext` 结构）。
    *   在这种情况下，Go 运行时会从这个 `ucontext` 中提取所有寄存器（包括浮点数），并将它们保存在协程结构体 `g` 的一个特殊字段中（`g.asyncSafePoint`）。
    *   这不属于“编译器自动保存”，而是“运行时被动保存”。

### 总结

Go 编译器“自动保存”寄存器的秘诀在于：

1.  它**不把协程切换当特殊情况处理**，而是将其视为一个**普通的、耗时很长的函数调用**。
2.  利用标准的**活跃性分析**，在调用发生前，生成汇编指令将后续需要的寄存器值**Spill（溢出/拷贝）到栈内存中**。
3.  因为 Go 的协程栈是连续且动态扩容的，这些数据就在该协程自己的栈上，安全且私密。

所以，是**函数调用规约**保证了数据的安全，而不是调度器去手动搬运寄存器。

`runtime.gopark` 是 Go 运行时中让 Goroutine **“主动放弃 CPU 并进入等待状态”** 的核心函数。

当 Goroutine 调用 `gopark` 时，它的状态会从 `_Grunning` 变为 `_Gwaiting`，并且**不会**被放回调度器的本地运行队列或全局队列。这意味着直到有人显式地唤醒它（通过 `runtime.goready`），否则它永远不会再被执行。

Go 源码中调用 `gopark` 的地方非常多，主要可以归纳为以下 **5 大类场景**。了解这些有助于你理解代码为什么会阻塞。

---

### 1. Channel 相关操作 (最常见)
这是 Go 并发模式中最核心的部分。当 Channel 不满足读写条件时，Goroutine 会被 park 住。

*   **向 nil 或满的 Channel 发送数据**：
    *   源码位置：`runtime.chansend`
    *   触发：`ch <- data` (当 buffer 满或 ch 为 nil)
    *   行为：当前 G 被挂起，加入到该 Channel 的发送等待队列 (`sendq`) 中。
*   **从 nil 或空的 Channel 接收数据**：
    *   源码位置：`runtime.chanrecv`
    *   触发：`<- ch` (当 buffer 空或 ch 为 nil)
    *   行为：当前 G 被挂起，加入到该 Channel 的接收等待队列 (`recvq`) 中。
*   **Select 语句阻塞**：
    *   源码位置：`runtime.selectgo`
    *   触发：`select { case ... }` (所有 case 都不满足且没有 default)
    *   行为：G 会同时链接到所有涉及 Channel 的等待队列中，然后 park。

---

### 2. 同步原语 (sync 包底层)
`sync` 包中的 Mutex, RWMutex, WaitGroup, Cond 等，底层都依赖信号量机制，而信号量的阻塞最终调用的是 `gopark`。

*   **获取锁被阻塞**：
    *   源码位置：`runtime.semacquire` (信号量获取)
    *   触发：`mutex.Lock()`, `rwmutex.RLock()`, `waitgroup.Wait()`
    *   说明：如果拿不到锁（CAS 失败且自旋多次后仍失败），Runtime 就会调用 `goparkunlock` 将 G 放入信号量的等待队列。
*   **条件变量等待**：
    *   源码位置：`runtime.sync_runtime_Semacquire`
    *   触发：`cond.Wait()`

---

### 3. 时间相关 (Time)
当 Goroutine 需要等待时间流逝时，它不能占着 CPU 空转，必须 park。

*   **睡眠**：
    *   源码位置：`runtime.timeSleep`
    *   触发：`time.Sleep(duration)`
    *   行为：G 被挂起，并注册一个 Timer 到计时器堆中。时间到了由计时器线程唤醒。
*   **Timer/Ticker 等待**：
    *   底层逻辑与 `timeSleep` 类似，依赖 Channel 通信，最终回落到 Channel 的阻塞上。

---

### 4. 网络 I/O (Network Poller)
Go 的高性能网络模型（Epoll/Kqueue/IOCP）依赖 `gopark` 来实现“伪阻塞”。

*   **网络读写阻塞**：
    *   源码位置：`runtime.netpollblock`
    *   触发：`conn.Read()`, `conn.Write()` (当 socket 缓冲区空或满时)
    *   机制：
        1.  用户调用 Read，底层 syscall 返回 `EAGAIN` (表示没数据)。
        2.  Runtime 调用 `netpollblock` -> `gopark`。
        3.  Goroutine 被挂在“网络轮询器”上，而不是普通的队列。
        4.  当网卡有数据到达，后台监控线程（sysmon）或调度器发现 epoll 就绪，调用 `goready` 唤醒该 G。

---

### 5. 运行时内部机制 (GC 与系统监控)
这些是你平时写代码看不到，但 Runtime 自己在用的。

*   **GC 辅助标记 (Mark Assist) 阻塞**：
    *   如果某些 Goroutine 分配内存太快，超过了 GC 扫描的速度，GC 会强制暂停这些 Goroutine (`runtime.gcAssistAlloc`)，调用 `gopark` 罚站一会儿，或者让它帮忙做 GC 工作。
*   **Stop The World (STW)**：
    *   在 GC 的特定阶段，需要暂停所有用户 Goroutine。调度器会通过抢占机制让所有运行中的 G 停下来并调用 `gopark`，状态记为 `_Gscan` 相关。
*   **Finalizer (终结器) 队列**：
    *   运行 Finalizer 的后台 Goroutine 如果发现没有对象需要清理，就会 park 住自己 (`runtime.runfinq`)。

---

### 总结表

| 场景 | 触发代码示例 | 阻塞原因 (`waitReason`) |
| :--- | :--- | :--- |
| **Channel** | `ch <- x` 或 `<-ch` | `chan send` / `chan receive` |
| **Select** | `select {}` | `select` |
| **Sleep** | `time.Sleep(1s)` | `sleep` |
| **Lock** | `mu.Lock()` | `semacquire` |
| **Network** | `conn.Read(buf)` | `IO wait` |
| **GC** | (自动触发) | `GC worker (idle)` 或 `GC assist wait` |

### 怎么验证？
你可以写一个阻塞的程序，然后发送 `SIGQUIT` (Ctrl+\) 或者调用 `runtime.Stack` 打印堆栈。
你会看到很多 Goroutine 处于 **`status: waiting`**，后面括号里的内容（例如 `chan receive`）就是 `gopark` 记录的阻塞原因。

Go 语言中，这种“自动终止执行并切换”的机制被称为**抢占式调度 (Preemption)**。

这里的核心在于：协程自己并不知道要停止，而是被“强行”暂停的。

Go 实现了两种抢占机制，分别对应不同的 Go 版本和场景。你问的“特殊的函数”和“原理”在这两种机制下截然不同：

---

### 1. 基于“函数调用”的协作式抢占 (旧机制，但仍在使用)

在 Go 1.14 之前，这是唯一的抢占方式。它的原理是**“埋雷”**。

*   **特殊的函数**：`runtime.morestack`
*   **原理**：
    1.  **编译器插桩**：Go 编译器会在每个函数（极小的内联函数除外）的开头（序言 Preamble）插入一段检查栈空间的代码。正常情况下，如果栈不够用了，会跳到 `runtime.morestack` 去扩容。
    2.  **埋雷 (Stack Poisoning)**：当调度器（通常是后台监控线程 `sysmon`）发现某个协程运行时间太长（超过 10ms）时，它无法直接暂停 CPU。它会把这个协程内存结构里的 `stackguard0`（栈扩容警戒线）设置为一个**极大值**（或者特定的魔法值）。
    3.  **引爆**：当这个协程**下一次调用任何函数**时，它执行函数开头的栈检查。因为警戒线被修改了，它误以为“栈不够用了”，于是跳到了 `runtime.morestack`。
    4.  **偷梁换柱**：进入 Runtime 内部后，Go 发现其实不是栈不够用，而是被标记为“需要被抢占”。于是，它不再扩容栈，而是直接调用 `runtime.gopark` 把当前协程挂起，并切换到下一个协程。

*   **缺点**：如果写了一个死循环 `for { i++ }` 且循环体内没有任何函数调用，这种机制就失效了，协程会永久霸占 CPU。

---

### 2. 基于“信号”的异步抢占 (Go 1.14+ 新机制)

为了解决死循环无法被抢占的问题，Go 1.14 引入了真正的**异步抢占**。

*   **特殊的信号**：`SIGURG` (在 Linux/Unix 上)
*   **特殊的函数**：`runtime.asyncPreempt` (汇编实现)
*   **原理**：

    1.  **监控者 (sysmon)**：
        Go 运行时有一个独立的后台线程叫 `sysmon`（System Monitor），它不绑定任何 P，专门负责监控。
    2.  **发现超时**：
        `sysmon` 也会每隔一段时间（20us ~ 10ms）醒来检查所有的 P（处理器）。如果发现某个 P 上的协程连续运行超过了 **10ms**。
    3.  **发送信号**：
        `sysmon` 会向运行该协程的**操作系统线程 (M)** 发送一个信号 —— **`SIGURG`**。
        *(注：选择 SIGURG 是因为它通常用于紧急套接字数据，对现有业务逻辑干扰最小)*
    4.  **操作系统中断**：
        操作系统收到信号，强制中断该线程当前的执行流（无论它正在算 1+1 还是在赋值），并跳转到 Go 注册的信号处理函数 `runtime.sighandler`。
    5.  **注入调用**：
        信号处理函数检查当前的上下文，确认这里是否可以安全抢占（例如没有持有 runtime 内部锁）。
        如果安全，它会修改被中断线程的**程序计数器 (PC)**，将其指向一个特殊的汇编函数 **`runtime.asyncPreempt`**，就像是在当前代码里强行插入了一行函数调用一样。
    6.  **执行切换**：
        当信号处理程序返回，线程恢复执行时，它首先执行的就是 `runtime.asyncPreempt`。这个函数会保存现场，然后调用 `runtime.mcall` -> `schedule`，从而完成切换。

---

### 总结：它是如何做到的？

Go 的“自动终止”其实是依靠**双保险**：

1.  **软策 (Function Check)**：在你调用函数的时候，利用栈检查机制，骗进 Runtime 进行切换。（**特殊函数：`runtime.morestack`**）
2.  **硬策 (Signal)**：如果你不调用函数，利用操作系统的信号机制，强行打断 CPU 执行流。（**特殊信号：`SIGURG`，特殊注入函数：`runtime.asyncPreempt`**）

这就是为什么现在的 Go 协程即使写了死循环，运行 10ms 后也会乖乖把 CPU 让出来给别人的原因。

<!-- 跳转链接 -->
[⬆️ 返回目录](#catalog)  |  [文章开头 ➡️](#chap-goroutineschedule)