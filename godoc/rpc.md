<div id="chap-rpc"></div>

[⬆️ 返回目录](#catalog)


## RPC

在 RPC（Remote Procedure Call，远程过程调用）中，**Stub** 之所以被翻译为 **“存根”**，主要是源于该单词在日常生活中的原意，以及它在计算机科学中引申出的**“占位符”**或**“代理”**的含义。

以下是详细的解释，分为语言学源头、技术含义和翻译逻辑三个层面：

### 1. 语言学源头：票根与支票存根
在英语中，**Stub** 一个非常常见的含义是指**“票据、支票等撕下后留下的那一小截”**（Counterfoil）。

*   **Ticket Stub**：票根。
*   **Check Stub**：支票存根。

**特点是：**
*   它**不是**票据或支票的主体（最有价值的部分已经给出去了）。
*   它**保留**在手中（本地）。
*   它**记录**了核心信息，用来证明或索引那笔交易。

### 2. 技术含义：RPC 中的 Stub 是做什么的？
在 RPC 架构中，客户端（Client）想要调用服务器（Server）上的某个函数（例如 `add(a, b)`）。但是这个函数不在本地，而在网络另一端的服务器上。

为了让客户端写代码时感觉像是在调用本地函数一样，RPC 框架会在客户端生成一段代码，这段代码就叫 **Client Stub**。

**Client Stub 的行为：**
1.  **空壳子**：它长得像那个函数（有同样的方法名、参数），但**里面没有实际的业务逻辑**。
2.  **负责打包**：它的作用只是把参数（a, b）打包（Marshalling），通过网络发给服务器。
3.  **等待结果**：它拿着服务器返回的结果，解包（Unmarshalling）后交给客户端。

**Server Stub 的行为：**
类似地，服务器端也有一个 Stub，负责接收网络包、解包、调用真正的业务逻辑、再打包结果发回。

### 3. 翻译逻辑：为什么叫“存根”？

将 Stub 翻译为“存根”，体现了以下隐喻：

*   **本地留存的凭证**：就像你开出一张支票（发起一个远程调用），真正的钱（计算逻辑）在银行（服务器）那边处理，你手里只留着一个**“存根”**（Stub 代码）。
*   **代表性**：这个 Stub 仅仅是远程完整程序的一个**代表**或**代理**，它本身是不完整的（只有接口，没有逻辑），就像票根不是整张票一样。
*   **占位符（Placeholder）**：它占据了函数的位置，但只是一小截代码片段。

### 4. 另一种常见的翻译：“桩”
值得注意的是，在软件工程的其他领域（特别是单元测试 Unit Testing），Stub 经常被翻译为 **“桩”**（如：打桩、桩代码）。

*   **测试中的 Stub**：是指为了测试某个模块，人为写的一个假对象来代替尚未完成的依赖项。这里的意象是“树桩”（Tree Stump），指砍掉大树后剩下的底座，用来顶替原来的位置。

**总结：**
*   在 **RPC** 语境下，强调的是“拿着这张票根去兑换远程服务”，所以偏向翻译为**“存根”**。
*   在 **测试** 语境下，强调的是“插在一个位置上的假模块”，所以偏向翻译为**“桩”**。

虽然现在技术圈子里大家习惯直接说英文 "Stub"，但“存根”这个翻译非常精准地捕捉了它**“位于本地、代表远程、本身只是个记录/接口”**的本质。

在 RPC（远程过程调用）架构中，**Client Stub**（客户端存根）和 **Server Stub**（服务端存根，有时也称为 **Skeleton** / 骨架）是实现“让远程调用看起来像本地调用”这一核心魔法的关键组件。

它们就像是位于网络两端的**“翻译官”**或**“打包员”**。

以下是它们的具体角色、职责以及交互流程的详细解析：

---

### 1. 核心概念图解

为了理解它们，我们可以看这个简化的流程：

```text
客户端程序 (Client App)
      │ 调用 add(1, 2)
      ▼
[ Client Stub ] ───> 负责“欺骗”客户端，让它以为是在调本地
      │ 1. 序列化参数 (Marshalling)
      │ 2. 发送网络请求
      ▼
    (网络 Network)
      ▼
[ Server Stub ] ───> 负责接收请求，它是服务端的门户
      │ 1. 反序列化参数 (Unmarshalling)
      │ 2. 调用真正的服务逻辑
      ▼
服务端具体实现 (Server Service)
      │ 执行 1 + 2 = 3
      │ 返回结果 3
      ▼
[ Server Stub ]
      │ 1. 序列化结果 (Marshalling)
      │ 2. 发送网络响应
      ▼
    (网络 Network)
      ▼
[ Client Stub ]
      │ 1. 反序列化结果 (Unmarshalling)
      │ 2. 返回 3 给客户端
      ▼
客户端程序 (Client App) 拿到结果
```

---

### 2. Client Stub（客户端存根）

Client Stub 位于客户端进程中，它的主要目的是**隐藏网络通信的复杂性**。

*   **身份：** 它是远程服务在本地的**代理（Proxy）**。
*   **职责：**
    1.  **提供接口：** 它向客户端程序暴露出与服务器端一模一样的接口（函数名、参数类型都一样）。
    2.  **参数打包（Marshalling）：** 当客户端调用它时，它将参数（如整数、对象、结构体）转换成可以在网络上传输的标准格式（通常是二进制流，如 Protobuf、JSON、XML 等）。
    3.  **添加元数据：** 它会把要调用的函数名称（或 ID）、序列号等信息打包进去。
    4.  **网络发送：** 调用底层网络库（如 TCP/IP socket），把打包好的数据发往服务器。
    5.  **等待与解包（Unmarshalling）：** 同步阻塞等待（或异步回调），收到服务器回包后，将二进制数据还原成编程语言中的返回值对象。

**一句话总结：** Client Stub 负责把“方法调用”变成“网络消息”。

---

### 3. Server Stub（服务端存根 / Skeleton）

Server Stub 位于服务端进程中，有时在旧的 RPC 文献（如 RMI）中被称为 **Skeleton（骨架）**。

*   **身份：** 它是服务端业务逻辑的**看门人（Gatekeeper）**。
*   **职责：**
    1.  **监听网络：** 接收来自网络的二进制消息包。
    2.  **参数解包（Unmarshalling）：** 将网络消息还原成服务端语言能识别的参数（变量、对象）。
    3.  **路由与分发（Dispatching）：** 根据消息中指明的函数名，决定调用本地具体的哪一个函数。
    4.  **调用业务逻辑：** 真正执行服务端开发者写的代码（例如查询数据库、复杂计算）。
    5.  **结果打包（Marshalling）：** 拿到业务逻辑的返回值（或异常信息），将其序列化为二进制流。
    6.  **回传：** 通过网络将结果发回给 Client Stub。

**一句话总结：** Server Stub 负责把“网络消息”变回“方法调用”。

---

### 4. 它们是怎么生成的？

你可能会问：*“每个函数都要手写这两个 Stub 吗？那岂不是累死了？”*

**不需要手写。** 它们通常是由**IDL（接口定义语言）**编译器自动生成的。

1.  **定义接口：** 开发者编写一个文件（如 `.proto` 文件或 `.thrift` 文件），定义好函数长什么样：
    ```protobuf
    // 举例 gRPC 的 Protobuf 定义
    service Calculator {
      rpc Add (AddRequest) returns (AddReply) {}
    }
    ```
2.  **代码生成：** 使用编译器（如 `protoc`）运行这个文件。
3.  **自动产出：** 编译器会自动生成：
    *   `client_stub.go` (给客户端用)
    *   `server_stub.go` (给服务端用)

### 5. 总结对比

| 特性 | Client Stub | Server Stub (Skeleton) |
| :--- | :--- | :--- |
| **位置** | 客户端 (Caller) | 服务端 (Callee) |
| **核心动作** | 序列化请求 -> 发送 -> 反序列化响应 | 反序列化请求 -> 调用真逻辑 -> 序列化响应 |
| **对用户透明** | 是 (用户感觉不到它的存在) | 是 (业务逻辑感觉不到网络的存在) |
| **作用对象** | 将**对象**转为**比特流** | 将**比特流**转为**对象** |

**为什么要这么设计？**
这种架构实现了**解耦**。客户端不需要知道服务器是用 Java 写的还是 Go 写的，也不需要知道数据是按什么字节序传输的。只要两边的 Stub 遵守同样的协议（Protocol），它们就能完美沟通。

**RPC (Remote Procedure Call)** 和 **RESTful (Representational State Transfer)** 是目前分布式系统和微服务架构中最主流的两种通信方式。

一句话总结它们的本质区别：**RPC 是面向“动作”的（我要调用这个函数），而 RESTful 是面向“资源”的（我要操作这个数据）。**

以下是详细的区别与联系分析：

---

### 一、 核心设计理念的区别（最本质的区别）

这是两者思维方式的根本不同。

#### 1. RPC：面向动作 (Action/Verb Oriented)
*   **思维方式：** 把远程通信看作是**本地函数调用的延伸**。
*   **URL 风格：** 这里的 URL 只是一个标识，往往包含动词。
*   **例子：**
    *   `POST /deleteUser?id=123`
    *   `POST /calculateSalary`
*   **潜台词：** “服务器，请帮我**执行** `deleteUser` 这个函数，参数是 123。”

#### 2. RESTful：面向资源 (Resource/Noun Oriented)
*   **思维方式：** 把网络上的所有东西都看作**资源（Resource）**，通过 HTTP 的标准动词（GET, POST, PUT, DELETE）来操作这些资源。
*   **URL 风格：** URL 中只有名词，表示资源的位置。
*   **例子：**
    *   `DELETE /users/123`
    *   `GET /salaries/employees/456`
*   **潜台词：** “服务器，我想**删除** `users/123` 这个资源。”

---

### 二、 具体技术层面的区别

| 维度 | RPC (以 gRPC/Thrift 为例) | RESTful (基于 HTTP/JSON) |
| :--- | :--- | :--- |
| **通信协议** | 通常基于 **TCP** 或 **HTTP/2** (gRPC)。协议更底层，灵活性高。 | 几乎完全基于 **HTTP/1.1** 或 HTTP/2。 |
| **数据格式** | **二进制** (如 Protobuf, Thrift)。数据极小，序列化/反序列化速度极快，但人类不可读。 | **文本** (主要是 JSON)。数据冗余大（有 Key 也有 Value），但人类可读，调试方便。 |
| **性能** | **高**。二进制传输 + 长连接，延迟低，吞吐量大。 | **中等**。JSON 解析慢，HTTP 头部信息冗余较多。 |
| **客户端调用** | **强类型，需要 Stub**。必须通过 IDL 生成代码，像调本地函数一样调用。 | **灵活**。直接发 HTTP 请求即可，不需要预先生成代码，任何能发 HTTP 的工具（如 Postman、浏览器）都能调。 |
| **耦合度** | **紧耦合**。服务端修改接口（如改了参数类型），客户端必须重新生成代码，否则报错。 | **松耦合**。只要 JSON 结构不大改，增加字段通常不影响旧客户端解析。 |

---

### 三、 它们的联系

虽然它们常被拿来比较，但它们并不是互斥的，甚至有血缘关系：

1.  **目的相同**：
    都是为了解决“**两台计算机之间如何交换数据**”这个问题。

2.  **RPC 可以基于 HTTP**：
    RPC 只是一个概念，它的底层传输层完全可以使用 HTTP。事实上，**gRPC 就是基于 HTTP/2 的**。以前也有 JSON-RPC 这种协议，它就是用 HTTP 发送 JSON 数据，但风格是 RPC 的（调用函数）。

3.  **REST 是一种风格，RPC 是一种协议/方法**：
    REST 是一套架构约束风格（Style），而 RPC 更像是一种具体的通信技术实现。

---

### 四、 什么时候用 RPC？什么时候用 RESTful？

这是架构选型中最常见的问题：

#### 1. 选用 RPC (尤其是 gRPC) 的场景：
*   **内部微服务之间 (East-West Traffic)**：A 服务调 B 服务，追求极致的性能和低延迟。
*   **强类型约束**：希望在编译阶段就发现参数错误，而不是等到运行时。
*   **多语言环境**：后端有 Java、Go、C++ 混合，通过 Protobuf 定义接口，自动生成各种语言的代码，非常方便。

#### 2. 选用 RESTful 的场景：
*   **对外 API (North-South Traffic)**：提供给第三方开发者、移动端 App、Web 前端使用的接口。因为 HTTP+JSON 是全球通用的，谁都能调，不需要下载专门的 SDK 或 Stub。
*   **资源操作简单**：由于业务本身就是简单的增删改查（CRUD），REST 的语义非常清晰。
*   **快速迭代与调试**：开发阶段需要频繁用浏览器或 Postman 查看返回结果，JSON 格式一目了然。

### 总结

*   **RPC 像打电话**：为了特定的事（函数），双方约定好语言（二进制协议），效率极高，但需要双方都有专门的电话机（Stub）。
*   **RESTful 像寄信/填表**：使用标准的信封（HTTP），里面写着通用的文字（JSON），虽然慢一点，大一点，但谁都能读懂，投递到哪里（URL）都很清晰。


这是一个非常深刻的问题。答案是：**如果不提前商量好，客户端完全不知道该怎么解析，通常会报错。**

HTTP 劫持（Hijack）本质上是**服务端单方面**撕毁了“我们要讲 HTTP 协议”的约定。如果客户端还在傻傻地等着 HTTP 响应（比如 `HTTP/1.1 200 OK`），而服务端直接发来一段二进制或者自定义文本，客户端就会因为**“格式错误（Malformed Response）”**而崩溃或报错。

为了让客户端能正确解析劫持后的数据，必须采用以下两种策略之一：

---

### 策略一：明文协商（最正规的做法，如 WebSocket）

这是最绅士的做法。服务端在动手劫持之前，会先发一个特殊的 HTTP 响应告诉客户端：“我要变身了！”

**流程如下：**

1.  **客户端发起请求**：带上一个标志，比如 `Connection: Upgrade` 和 `Upgrade: websocket`。
    > *潜台词：“老板，能不能别讲 HTTP 了，我们换 WebSocket 聊聊？”*
2.  **服务端同意并发送信号**：
    服务端在调用 `Hijack` 之前，**必须**先写入一个标准的 HTTP 响应头，状态码是 **101**。
    ```http
    HTTP/1.1 101 Switching Protocols
    Upgrade: websocket
    Connection: Upgrade
    ```
    > *潜台词：“好的，收到。发完这条消息后，我们就切换频道。”*
3.  **客户端收到 101 响应**：
    客户端看到 `101` 状态码，它内部的代码逻辑就会**切换解析器**。它不再期待 HTTP Header，而是开始按照 WebSocket 的帧格式去解析后续的字节流。
4.  **服务端 Hijack**：
    这时候服务端才真正劫持连接，发送 WebSocket 数据。

**如果服务端不发 101 直接 Hijack 发数据？**
客户端（如浏览器）会报错：`Parse Error: Expected HTTP/1.1 200 OK`，因为它还在等 HTTP 头。

---

### 策略二：隐式约定（Go RPC 的做法）

这是“熟人之间”的做法。客户端和服务端是同一个程序员写的（或者用了同一个框架），大家心里有数。

**流程如下：**

1.  **客户端代码（Go RPC Client）**：
    它不是一个通用的 HTTP 浏览器，它是一个专门的 RPC 客户端。
    它发送 `CONNECT /_goRPC_ HTTP/1.0`。
    **关键点：** 发送完这个请求后，客户端的代码逻辑**假定**只要连接没断，后续发来的数据就是 RPC 格式。
2.  **服务端 Hijack**：
    服务端收到请求，直接劫持，**不发 HTTP 101，也不发 HTTP 200**（或者只发个简单的确认字符）。直接开始发 RPC 的二进制流。
3.  **客户端解析**：
    客户端不需要看状态码（或者只看一个极其简单的回执）。因为它被设计成：只要连上了这个 URL，我就切换到底层的 TCP 读取模式，按 RPC 协议解包。

**如果用浏览器去访问这个 URL 会怎样？**
浏览器发了 GET 请求，服务端劫持并回传了二进制数据。浏览器一看：“这啥呀？不是 HTTP 格式”，然后显示“网页无法运作”或者直接下载了一个名为 `_goRPC_` 的乱码文件。

---

### 深入理解：客户端也需要“劫持”吗？

是的，对称的。

如果通信协议从 HTTP 变成了 TCP（Raw Socket），不仅服务端要通过 `Hijack` 拿到 `net.Conn`，**客户端也必须拿到底层的 `net.Conn`**。

*   **对于 Go 的 `net/http` 客户端：**
    标准的 `http.Get()` 方法是封装得很死的，你很难从中拿到底层的 TCP 连接。
*   **所以：**
    那些需要协议切换的客户端（如 WebSocket 库、RPC 库），通常**不会**直接使用标准的 `http.Client` 去发请求，而是使用 `net.Dial` 建立 TCP 连接，手动写一句 `GET /... HTTP/1.1\r\n` 来模拟 HTTP 握手，一旦握手成功，它们手里本来就握着 TCP 连接 (`conn`)，直接继续读写即可。

### 总结

服务端劫持了连接后，客户端**不会**自动知道怎么解析。

*   **普通客户端（浏览器/Curl）**：必须看到 `HTTP 101 Switching Protocols` 响应，才会切换模式。
*   **专用客户端（RPC Client）**：依靠**代码里的硬编码逻辑**（约定），只要请求发出去了，就默认后续是新协议。

所以，`http.Hijacker` 就像是把电话线拔下来接到了对讲机上。如果对方不知道你要换设备，他还在电话那头“喂喂喂”，是听不到你对讲机里的声音的。

这是一个非常好的架构设计问题。既然最终都要“脱掉外衣”跑裸 TCP，为什么不一开始就直接裸奔（直接用 TCP Socket），非要穿一件 HTTP 的衣服混进门再脱掉呢？

这主要出于**兼容性**、**复用性**和**运维成本**的考量。

这就好比：**为什么要买一张电影票进场，进去之后却是在睡觉？**
因为买票进场这个机制（HTTP）非常成熟、通用，且能帮你解决掉门卫（防火墙）和座位分配（路由）的问题。

以下是具体的四大理由：

### 1. 穿透防火墙与中间设备（最现实的理由）
在现实的网络环境中，路由器、防火墙和代理服务器通常非常严苛。
*   **TCP 困境**：如果你发明了一个自定义协议，跑在端口 `9527` 上。很多公司的内网防火墙、云厂商的安全组默认策略是**“拒绝所有非标准端口”**。你必须去申请开通端口，这在很多企业里流程极慢。
*   **HTTP 优势**：端口 `80` (HTTP) 和 `443` (HTTPS) 几乎在所有网络中都是开放的。
    通过 HTTP 握手开始，可以伪装成正常的网页流量，骗过防火墙的初步检查，建立连接后再切换协议。这就是所谓的**“HTTP 隧道（Tunneling）”**。

### 2. 端口复用（Port Multiplexing）
这是 Go 这种设计最聪明的地方。
想象一下，你的服务器只有一个 IP，只开放一个端口 `8080`。

*   **如果用纯 TCP**：这个端口一旦被 RPC 服务占用了，就不能给别用了。因为 TCP 握手后直接发二进制流，Web 浏览器连上来根本听不懂。
*   **如果用 HTTP 握手**：你可以根据 **URL 路径** 来分发流量！
    *   `GET /images/logo.png` -> 分发给静态文件处理。
    *   `GET /api/user` -> 分发给 RESTful API 处理器。
    *   `CONNECT /_goRPC_` -> **识别出是 RPC 请求，Hijack 掉，转给 RPC 处理器**。
    *   `GET /ws/chat` -> 识别出是 WebSocket，Hijack 掉，转给聊天处理器。

**意义**：同一个端口，既能通过浏览器看监控页面，又能跑高性能 RPC 服务，还能跑 WebSocket。这就大大降低了运维部署的复杂度。

### 3. 利用现成的 HTTP 基础设施（鉴权与元数据）
HTTP 协议虽然文本比较大，但它定义的 Header 机制非常完善。

*   **鉴权（Authentication）**：在 Hijack 之前，你可以直接复用 Web 系统的鉴权逻辑。
    *   客户端发请求带上 `Authorization: Bearer token...`。
    *   服务端在 `ServeHTTP` 里先校验 Token。
    *   **校验失败**：直接回 `401 Unauthorized`（标准的 HTTP 错误，客户端都能看懂）。
    *   **校验成功**：才调用 `Hijack()` 开始传输二进制数据。
    *   *如果是纯 TCP，你得自己设计一套鉴权握手协议，还要处理鉴权失败该发什么字节码，很麻烦。*

*   **负载均衡（Load Balancing）**：Nginx 或 L7 负载均衡器可以读取 HTTP Path。它可以把 `/rpc` 的流量转发给后端集群 A，把 `/web` 的流量转发给后端集群 B。如果是纯 TCP，L7 负载均衡器就瞎了。

### 4. 协议协商（Upgrade 机制）
HTTP 提供了一个标准的“商量”机制。
客户端说：“我想用 WebSocket，行不行？”（`Upgrade: websocket`）
服务端说：“行！”（`101 Switching Protocols`）或者“不行，版本太低”（`400 Bad Request`）。

这种**“握手-协商-升级”**的标准流程，让服务端可以优雅地处理版本不兼容的情况，而不是一上来就发一堆对方看不懂的二进制乱码。

---

### 总结

一开始使用 HTTP 协议，是为了**“借道”**。

1.  **借路**：借用 80/443 端口穿透防火墙。
2.  **借地**：借用 URL 路径实现多服务共存。
3.  **借势**：借用 HTTP 现有的 Cookie、Header、Token 鉴权机制。

一旦这些“过安检”的工作做完了，为了追求性能，马上通过 `Hijack` 把 HTTP 这层厚重的外衣脱掉，开始裸跑 TCP。这是**“进门讲礼貌（HTTP），干活讲效率（TCP）”**的最佳结合。

<!-- 跳转链接 -->
[⬆️ 返回目录](#catalog)  |  [文章开头 ➡️](#chap-prc)